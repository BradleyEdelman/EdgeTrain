{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a7a2f4-4683-4ae2-908a-57f4a079d77e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3096e15-5b6c-412d-9342-33e640c7c733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Workspace/Users/bjedelma@gmail.com/ScaleML/scaleml')\n",
    "import scaleml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cce1389-9ae2-413a-a9ff-bf59e57e47c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Detect computational resources on current node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43cf733-8786-4f8b-8c4b-1adaa5e37333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Detect computing resources\n",
    "detected_resources = scaleml.resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b221868-15b5-487b-a65b-b17a8b9e214c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specify ML frameworks for the model and distributed strategy\n",
    "framework = {\n",
    "    \"model\": \"tensorflow\",\n",
    "    \"strategy\": \"tensorflow\",\n",
    "}\n",
    "\n",
    "# Set the distributed training strategy\n",
    "dist_strategy = scaleml.strategies(framework, detected_resources, resource_type='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805d6dba-0acf-4b10-a813-a85875a9917b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset for example\n",
    "import tensorflow as tf\n",
    "\n",
    "# MNIST as example model and dataset (you can replace with your actual dataset/model)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data: normalize and reshape\n",
    "train_images = train_images.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "test_images = test_images.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Select half the train data\n",
    "index = len(train_images) // 8\n",
    "train_images, train_labels = train_images[:index], train_labels[:index]\n",
    "\n",
    "# Combine train images and labels in a dictionary\n",
    "train_dataset = {\n",
    "    \"images\": train_images,\n",
    "    \"labels\": train_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f8b8d9b-4ae3-400d-a51f-84b91b5e50ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Train model with distributed strategy\n",
    "# history, history_file, log_file = scaleml.distributed_train(framework, dist_strategy, train_dataset, log_resources=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e73845c-6b85-4320-898a-50e72c40630e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def distributed_train(framework, strategy, train_dataset, log_resources=True):\n",
    "strategy = dist_strategy\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from multiprocessing import Process, Value\n",
    "import os, time, pickle\n",
    "\n",
    "from scaleml import create_scaleml_folders, create_model_tf, create_model_torch, start_logging, stop_logging\n",
    "\n",
    "# create folders for saving\n",
    "scaleml_folder = create_scaleml_folders()\n",
    "print(f\"Scaleml folder and subfolders are set up at: {scaleml_folder}\")\n",
    "print()\n",
    "\n",
    "# log resource use throughout training\n",
    "log_dir = f\"{scaleml_folder}/logs/\"\n",
    "log_file = f\"{log_dir}/{datetime.now().strftime('%Y%m%d')}_resource_usage_log.csv\"\n",
    "# if log_resources:        \n",
    "# Start logging resources in the background (adjust the interval as needed)\n",
    "# log_process = start_logging(log_file, interval=10)\n",
    "print()\n",
    "\n",
    "# Detect size of the first image from train_dataset\n",
    "train_images = train_dataset.get('images')\n",
    "train_labels = train_dataset.get('labels')\n",
    "input_shape = train_images[0].shape\n",
    "\n",
    "# Save the model\n",
    "log_time = log_file.split('/')[-1]\n",
    "log_time = log_time.split('_')[0]\n",
    "\n",
    "# Start the training process with or without resource monitoring\n",
    "if framework.get('strategy') == 'tensorflow':\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model_tf(input_shape, model_path=None)\n",
    "        \n",
    "    model.save(os.path.join(f\"{scaleml_folder}/models/\", f\"{log_time}_tf_model.h5\"))\n",
    "\n",
    "    history = model.fit(train_images, train_labels, epochs=2, batch_size=64, verbose=1)\n",
    "    history_file = os.path.join(f\"{scaleml_folder}/models/\", f\"{log_time}_tf_model_history.pkl\")\n",
    "    # with open(history_file, 'wb') as f:\n",
    "    #     pickle.dump(history.history, f)\n",
    "\n",
    "elif framework.get('strategy') == 'pytorch':\n",
    "\n",
    "    pass\n",
    "\n",
    "    # history_file = os.path.join(f\"{scaleml_folder}/models/\", f\"{log_time}_torch_model_history.pkl\")\n",
    "    # with open(history_file, 'wb') as f:\n",
    "    #         pickle.dump(history.history, f)\n",
    "\n",
    "# if log_resources:\n",
    "# Stop the logging once training is complete\n",
    "# stop_logging(log_process)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "# return history, history_file, log_file"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "single_node_tensorflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
