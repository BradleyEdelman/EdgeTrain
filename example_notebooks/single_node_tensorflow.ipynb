{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3096e15-5b6c-412d-9342-33e640c7c733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Workspace/Users/bjedelma@gmail.com/ScaleML/scaleml')\n",
    "import scaleml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cce1389-9ae2-413a-a9ff-bf59e57e47c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Detect computational resources on current node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43cf733-8786-4f8b-8c4b-1adaa5e37333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "detected_resources = scaleml.resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17fe164b-2bd9-43a8-be10-7f0f03c44b2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Specify distributed strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a827eea-8a82-43a2-b547-ff65a5678774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "framework = {\n",
    "    \"model\": \"tensorflow\",\n",
    "    \"strategy\": \"tensorflow\",\n",
    "}\n",
    "framework.get('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b221868-15b5-487b-a65b-b17a8b9e214c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Input as a dictionary\n",
    "framework = {\n",
    "    \"model\": \"tensorflow\",\n",
    "    \"strategy\": \"tensorflow\",\n",
    "}\n",
    "\n",
    "scaleml.dist_strategy = scaleml.strategies(framework, detected_resources, devices='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50bbc4e-3b01-4950-9a2e-fc72717f18ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Sets up a distributed training strategy based on the chosen framework, available resources, and specified devices.\n",
    "\n",
    "Args:\n",
    "    framework (dict): A dictionary containing the framework details.\n",
    "                        Expected keys: 'model', 'strategy'.\n",
    "                        Options for 'model': 'tensorflow', 'pytorch'.\n",
    "                        Options for 'strategy': 'tensorflow', 'pytorch', 'horovod'.\n",
    "    detected_resources (dict): A dictionary containing the detected resources. \n",
    "                        Expected keys: 'logical_cores', 'gpu_devices'.\n",
    "    devices (str): The type of devices to use. Options: 'cpu', 'gpu', 'all'.\n",
    "\n",
    "Returns:\n",
    "    Distributed ScaleML training strategy appropriate for the model.\n",
    "\"\"\"\n",
    "\n",
    "# Check if detected resources are provided, if not raise an error.\n",
    "if detected_resources is None:\n",
    "    raise ValueError(\"Resources must be provided. Use the 'resources()' function to detect resources.\")\n",
    "    \n",
    "# Extract logical cores and GPU devices from detected resources.\n",
    "logical_cores = [i for i, resource in enumerate(resources) if 'cpu' in resource]\n",
    "gpu_devices = [i for i, resource in enumerate(resources) if 'gpu' in resource]\n",
    "if devices in ['gpu', 'all'] and not gpu_devices:\n",
    "    print(\"No GPUs exist. Only using CPU resources.\")\n",
    "    devices = 'cpu'\n",
    "\n",
    "# extract framework assignments\n",
    "framework_model = framework.get('model')\n",
    "framework_strategy = framework.get('strategy')\n",
    "\n",
    "\n",
    "# Create a istributed strategy depending on the input framework\n",
    "if framework_strategy.lower() == 'tensorflow':\n",
    "    \n",
    "    if framework_model.lower() != 'tensorflow':\n",
    "        raise ValueError(\"Incompatible model for TensorFlow strategy. Please use a TensorFlow model.\")\n",
    "    else:\n",
    "        import tensorflow as tf\n",
    "        \n",
    "        # TensorFlow strategy setup\n",
    "        if devices == 'all':\n",
    "            strategy = tf.distribute.MirroredStrategy()\n",
    "        elif devices == 'gpu' and gpu_devices:\n",
    "            strategy = tf.distribute.MirroredStrategy(devices=[f\"/gpu:{i}\" for i in range(len(gpu_devices))])\n",
    "        else:\n",
    "            strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "        print(f\"TensorFlow strategy initialized: {strategy}\")\n",
    "        return strategy\n",
    "\n",
    "elif framework_strategy.lower() == 'pytorch':\n",
    "    \n",
    "    if framework_model.lower() != 'pytorch':\n",
    "        raise ValueError(\"Incompatible model for PyTorch strategy. Please use a PyTorch model.\")\n",
    "    else:\n",
    "        import torch\n",
    "        \n",
    "        # PyTorch device setup\n",
    "        if devices == 'all':\n",
    "            strategy = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        elif devices == 'gpu' and gpu_devices:\n",
    "            strategy = torch.device(\"cuda\")\n",
    "        else:\n",
    "            strategy = torch.device(\"cpu\")\n",
    "        print(f\"PyTorch device: {strategy}\")\n",
    "        return strategy\n",
    "\n",
    "elif framework_strategy.lower() == 'horovod':\n",
    "    \n",
    "    import horovod.tensorflow as hvd_tf\n",
    "    import horovod.torch as hvd_torch\n",
    "    \n",
    "    if framework_model.lower() == 'tensorflow':\n",
    "        hvd_tf.init()\n",
    "        print(f\"Horovod TensorFlow rank: {hvd_tf.rank()}, size: {hvd_tf.size()}\")\n",
    "        \n",
    "        if gpu_devices:\n",
    "            import tensorflow as tf\n",
    "            tf.config.experimental.set_visible_devices(gpu_devices[hvd_tf.local_rank()], 'GPU')\n",
    "        return hvd_tf\n",
    "    \n",
    "    elif framework_model.lower() == 'pytorch':\n",
    "        hvd_torch.init()\n",
    "        print(f\"Horovod PyTorch rank: {hvd_torch.rank()}, size: {hvd_torch.size()}\")\n",
    "        \n",
    "        if gpu_devices:\n",
    "            import torch\n",
    "            torch.cuda.set_device(hvd_torch.local_rank())\n",
    "        return hvd_torch\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unsupported framework or model. Choose from 'tensorflow', 'pytorch', or 'horovod'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36326ec5-2c3c-428f-8775-18f573694b26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load MNIST dataset for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "805d6dba-0acf-4b10-a813-a85875a9917b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# MNIST as example model and dataset (you can replace with your actual dataset/model)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to a range of 0 to 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Flatten the images\n",
    "train_images = train_images.reshape(-1, 784)\n",
    "test_images = test_images.reshape(-1, 784)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(64)\n",
    "\n",
    "display(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "384fa1a6-7a72-4e2a-abd5-2595ee42a2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f8b8d9b-4ae3-400d-a51f-84b91b5e50ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scaleml.distributed_train(detected_resources, framework, strategy, train_dataset, log_resources=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05b22d70-93b2-4265-ae35-8b9350e10eef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def distributed_train(detected_resources, framework, strategy, train_dataset, log_resources=True):\n",
    "    \"\"\"\n",
    "    Train a model using a ScaleML strategy and track resource usage (optional).\n",
    "    \n",
    "    Parameters:\n",
    "    - detected_resources (dict): A dictionary containing the detected resources. \n",
    "                         Expected keys: 'logical_cores', 'gpu_devices'.\n",
    "    - framework (dict): A dictionary containing the framework details.\n",
    "                         Expected keys: 'model', 'strategy'.\n",
    "                         Options for 'model': 'tensorflow', 'pytorch'.\n",
    "                         Options for 'strategy': 'tensorflow', 'pytorch', 'horovod'.\n",
    "    - strategy: ScaleML strategy for distributed training.\n",
    "    - train_dataset: Dataset used for training.\n",
    "    - log_resources: Boolean flag to enable/disable resource logging.\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    import torch\n",
    "    import horovod.tensorflow as hvd_tf\n",
    "    import horovod.torch as hvd_torch\n",
    "\n",
    "    # log resource use throughout training\n",
    "    if log_resources:\n",
    "        if not detected_resources:\n",
    "            raise ValueError(\"Please include output from resources() to log resources\")\n",
    "        \n",
    "        # Start logging resources in the background (you can adjust the interval as needed)\n",
    "        log_resource_usage(detected_resources, interval=10)\n",
    "    \n",
    "    # Detect size of the first image from train_dataset\n",
    "    for images, labels in train_dataset.take(1):\n",
    "        input_shape = images.shape[1:]\n",
    "        break\n",
    "\n",
    "    # create model based on the detected framework\n",
    "    model = create_model(framework, input_shape)\n",
    "    \n",
    "    # Start the training process with or without resource monitoring\n",
    "    if isinstance(strategy, tf.distribute.Strategy):\n",
    "\n",
    "        with strategy.scope():\n",
    "            history = model.fit(train_dataset, epochs=20)\n",
    "            return history\n",
    "\n",
    "    elif isinstance(strategy, torch.device):\n",
    "        model.to(strategy)\n",
    "        history = train_pytorch_model(model, train_dataset, epochs=20)\n",
    "        return history\n",
    "\n",
    "    elif 'horovod' in str(type(strategy)).lower():\n",
    "        \n",
    "        if 'tensorflow' in str(type(strategy)).lower():\n",
    "            history = model.fit(train_dataset, epochs=20)\n",
    "            return history\n",
    "        elif 'torch' in str(type(strategy)).lower():\n",
    "            model.to(strategy)\n",
    "        history = train_pytorch_model(model, train_dataset, epochs=20)\n",
    "        return history\n",
    "\n",
    "    if log_resources:\n",
    "        # Stop the logging once training is complete\n",
    "        stop_event.set()\n",
    "    \n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d97da134-01a7-4fa9-bdb9-c8ae4fef628f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def strategies(framework, detected_resources, devices):\n",
    "    \"\"\"\n",
    "    Sets up a distributed training strategy based on the chosen framework, available resources, and specified devices.\n",
    "\n",
    "    Args:\n",
    "        framework (dict): A dictionary containing the framework details.\n",
    "                         Expected keys: 'model', 'strategy'.\n",
    "                         Options for 'model': 'tensorflow', 'pytorch'.\n",
    "                         Options for 'strategy': 'tensorflow', 'pytorch', 'horovod'.\n",
    "        detected_resources (dict): A dictionary containing the detected resources. \n",
    "                         Expected keys: 'logical_cores', 'gpu_devices'.\n",
    "        devices (str): The type of devices to use. Options: 'cpu', 'gpu', 'all'.\n",
    "\n",
    "    Returns:\n",
    "        Distributed ScaleML training strategy appropriate for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if detected resources are provided, if not raise an error.\n",
    "    if detected_resources is None:\n",
    "        raise ValueError(\"Resources must be provided. Use the 'resources()' function to detect resources.\")\n",
    "        \n",
    "    # Extract logical cores and GPU devices from detected resources.\n",
    "    logical_cores = detected_resources.get('logical_cores', 0)\n",
    "    gpu_devices = detected_resources.get('gpu_devices', [])\n",
    "    if devices == 'gpu' and not gpu_devices:\n",
    "        print(\"No GPUs exist. Only using CPU resources.\")\n",
    "        devices = 'cpu'\n",
    "\n",
    "    # extract framework assignments\n",
    "    framework_model = framework.get('model')\n",
    "    framework_strategy = framework.get('strategy')\n",
    "    \n",
    "\n",
    "    # Create a istributed strategy depending on the input framework\n",
    "    if framework_strategy.lower() == 'tensorflow':\n",
    "        \n",
    "        if framework_model.lower() != 'tensorflow':\n",
    "            raise ValueError(\"Incompatible model for TensorFlow strategy. Please use a TensorFlow model.\")\n",
    "        else:\n",
    "            import tensorflow as tf\n",
    "            \n",
    "            # TensorFlow strategy setup\n",
    "            if devices == 'all':\n",
    "                strategy = tf.distribute.MirroredStrategy()\n",
    "            elif devices == 'gpu' and gpu_devices:\n",
    "                strategy = tf.distribute.MirroredStrategy(devices=[f\"/gpu:{i}\" for i in range(len(gpu_devices))])\n",
    "            else:\n",
    "                strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "            print(f\"TensorFlow strategy initialized: {strategy}\")\n",
    "            return strategy\n",
    "\n",
    "    elif framework_strategy.lower() == 'pytorch':\n",
    "        \n",
    "        if framework_model.lower() != 'pytorch':\n",
    "            raise ValueError(\"Incompatible model for PyTorch strategy. Please use a PyTorch model.\")\n",
    "        else:\n",
    "            import torch\n",
    "            \n",
    "            # PyTorch device setup\n",
    "            if devices == 'all':\n",
    "                strategy = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            elif devices == 'gpu' and gpu_devices:\n",
    "                strategy = torch.device(\"cuda\")\n",
    "            else:\n",
    "                strategy = torch.device(\"cpu\")\n",
    "            print(f\"PyTorch device: {strategy}\")\n",
    "            return strategy\n",
    "\n",
    "    elif framework_strategy.lower() == 'horovod':\n",
    "        \n",
    "        import horovod.tensorflow as hvd_tf\n",
    "        import horovod.torch as hvd_torch\n",
    "        \n",
    "        if framework_model.lower() == 'tensorflow':\n",
    "            hvd_tf.init()\n",
    "            print(f\"Horovod TensorFlow rank: {hvd_tf.rank()}, size: {hvd_tf.size()}\")\n",
    "            \n",
    "            if gpu_devices:\n",
    "                import tensorflow as tf\n",
    "                tf.config.experimental.set_visible_devices(gpu_devices[hvd_tf.local_rank()], 'GPU')\n",
    "            return hvd_tf\n",
    "        \n",
    "        elif framework_model.lower() == 'pytorch':\n",
    "            hvd_torch.init()\n",
    "            print(f\"Horovod PyTorch rank: {hvd_torch.rank()}, size: {hvd_torch.size()}\")\n",
    "            \n",
    "            if gpu_devices:\n",
    "                import torch\n",
    "                torch.cuda.set_device(hvd_torch.local_rank())\n",
    "            return hvd_torch\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported framework or model. Choose from 'tensorflow', 'pytorch', or 'horovod'.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "single_node_tensorflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
